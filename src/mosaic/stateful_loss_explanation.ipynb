{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91641a39",
   "metadata": {},
   "source": [
    "A desired quality for some loss functions is **statefulness**, meaning that it utilizes on an internally stored and mutable variable for the loss computation. \\\n",
    "This is incompatible with the design philosophy of JAX, which forces functions to be **pure**, exatly meaning that the function do not rely on hidden states."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db252c2",
   "metadata": {},
   "source": [
    "To work around this problem the guys from mosaic adapt the method describe in `common.py`:\n",
    "   1. a module has a `state_index` property that is an instance of `StateIndex`\n",
    "   2. part of the aux pytree is a tuple of (StateIndex, value) where value is the argument to be passed to the `update_state` method\n",
    "   3. the `update_state` method is called for each module in the loss pytree that has a `state_index` property\n",
    "   This last step happens in the optimization loop after the value and gradient have been computed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03b7111",
   "metadata": {},
   "source": [
    "In mosaic a loss function is an object created using the `build_loss` method of any of the supported models. \\\n",
    "It contains multiple relevant parameters for loss computation, but in particular it has a `loss` property containing either a `LinearCombination` or single `LossTerm` object, representing the actual classes that perform the loss computation. \\\n",
    "It is the single `LossTerm` that we want to allow to be stateful.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ca8244",
   "metadata": {},
   "source": [
    "We demonstrate an example of a dummy stateful loss and its integration in an optimization pipeline using the `ProtenixTiny` model. \\\n",
    "So first thing first, the model is loaded and the input features representing the target-binder complex are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ee33149",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2026-02-23 16:31:56,916:jax._src.xla_bridge:834: Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n",
      "2026-02-23 16:31:56,916 [/home/marco/DTU/ms_thesis/code/mosaic_motif_scaffolding/.venv/lib/python3.12/site-packages/jax/_src/xla_bridge.py:834] INFO jax._src.xla_bridge: Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/marco/DTU/ms_thesis/code/mosaic_motif_scaffolding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-23 16:31:57,897 [/home/marco/DTU/ms_thesis/code/mosaic_motif_scaffolding/.venv/lib/python3.12/site-packages/protenix/web_service/colab_request_utils.py:195] ERROR protenix.web_service.colab_request_utils: Msa server is running.\n",
      "COMPLETE: 100%|██████████| 100/100 [elapsed: 00:01 estimate remaining: 00:00]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files downloaded and extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2026-02-23 16:32:03,577 [/home/marco/DTU/ms_thesis/code/mosaic_motif_scaffolding/.venv/lib/python3.12/site-packages/protenix/data/constraint_featurizer.py:392] INFO protenix.data.constraint_featurizer: Loaded constraint feature: #atom contact:0 #contact:0 #pocket:0\n"
     ]
    }
   ],
   "source": [
    "import jax \n",
    "import equinox as eqx\n",
    "import numpy as np\n",
    "from mosaic.losses import structure_prediction as sp\n",
    "from mosaic.models.protenix import ProtenixTiny\n",
    "from mosaic.structure_prediction import TargetChain\n",
    "import gemmi\n",
    "%cd \"/home/marco/DTU/ms_thesis/code/mosaic_motif_scaffolding\"\n",
    "\n",
    "# Load model\n",
    "protenix = ProtenixTiny()\n",
    "\n",
    "# Define binder length and target structure\n",
    "binder_length = 120\n",
    "target_structure = gemmi.read_structure(\"IL7RA.cif\")\n",
    "target_structure.remove_ligands_and_waters()\n",
    "target_sequence = gemmi.one_letter_code(\n",
    "    [r.name for r in target_structure[0][0]]\n",
    ")\n",
    "\n",
    "# Build complex input features\n",
    "design_features, design_structure = protenix.binder_features(\n",
    "    binder_length=binder_length,\n",
    "    chains=[\n",
    "        TargetChain(\n",
    "            target_sequence,\n",
    "            use_msa=True,\n",
    "            template_chain=target_structure[0][0],\n",
    "        )\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f6895c",
   "metadata": {},
   "source": [
    "In addition to standard losses, we implement a dummy stateful loss. \\\n",
    "As described above, a stateful loss needs to have: \n",
    "- a `state_index` property acting as a unique identifier for the loss, \n",
    "- the internal `state` property which is the mutable part of the loss, \n",
    "- an `update_state` function describing how the state should modified using the new state stored in the output `aux` PyTree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77fcf916",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mosaic.common import StateIndex, LossTerm\n",
    "from jaxtyping import Float, Array\n",
    "\n",
    "# dummy stateful loss\n",
    "class StatefulLoss(LossTerm):\n",
    "    state_index: StateIndex\n",
    "    state: float = 0.0\n",
    "    \n",
    "    def __call__(\n",
    "        self,\n",
    "        sequence: Float[Array, \"N 20\"],\n",
    "        output: sp.AbstractStructureOutput,\n",
    "        key):\n",
    "        # Some random loss computation\n",
    "        loss = 10\n",
    "        next_state = self.state + 1\n",
    "        return loss, {\"stateful_loss\": loss, \"dummy\": (self.state_index, next_state)}\n",
    "    \n",
    "    # remember that the new_state is read from aux which are always jax arrays\n",
    "    def update_state(self, new_state):\n",
    "        new_state = new_state.item()\n",
    "        return eqx.tree_at(lambda s: s.state, self, new_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2eb0c1",
   "metadata": {},
   "source": [
    "Now we can build and run the loss function..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "063e8201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_msa 209\n",
      "JIT compiling protenix trunk module...\n"
     ]
    }
   ],
   "source": [
    "# Build custom loss function\n",
    "structure_loss = (\n",
    "    sp.BinderTargetContact()\n",
    "    + sp.WithinBinderContact()\n",
    "    + StatefulLoss(state_index=StateIndex(), state=5.0)\n",
    "    + StatefulLoss(state_index=StateIndex(), state=0.0)\n",
    ")\n",
    "\n",
    "# Add logging of specific features across optimization\n",
    "loss_fn = protenix.build_multisample_loss(\n",
    "    loss=structure_loss,\n",
    "    features=design_features,\n",
    "    recycling_steps=1,\n",
    "    sampling_steps=20,\n",
    "    num_samples=4\n",
    ")\n",
    " \n",
    "pssm = jax.nn.softmax(0.5 * jax.random.gumbel(key=jax.random.key(np.random.randint(1000000)), shape=(binder_length, 20)))\n",
    "loss, aux = loss_fn(sequence=pssm, key=jax.random.key(42))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adec5d4",
   "metadata": {},
   "source": [
    "Inspecting the outputs, we can verify the presence of the `(StateIndex, new_state)` tuple in the aux of the `StatefulLoss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de7051f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 30.135160446166992\n",
      "(SequenceKey(idx=0), DictKey(key='target_contact')): [-5.030611 -5.030611 -5.030611 -5.030611]\n",
      "(SequenceKey(idx=1), DictKey(key='intra_contact')): [-5.10455 -5.10455 -5.10455 -5.10455]\n",
      "(SequenceKey(idx=2), DictKey(key='dummy'), SequenceKey(idx=0), GetAttrKey(name='id')): [50340 50340 50340 50340]\n",
      "(SequenceKey(idx=2), DictKey(key='dummy'), SequenceKey(idx=1)): [6. 6. 6. 6.]\n",
      "(SequenceKey(idx=2), DictKey(key='stateful_loss')): [10 10 10 10]\n",
      "(SequenceKey(idx=3), DictKey(key='dummy'), SequenceKey(idx=0), GetAttrKey(name='id')): [26007 26007 26007 26007]\n",
      "(SequenceKey(idx=3), DictKey(key='dummy'), SequenceKey(idx=1)): [1. 1. 1. 1.]\n",
      "(SequenceKey(idx=3), DictKey(key='stateful_loss')): [10 10 10 10]\n",
      "(SequenceKey(idx=4), DictKey(key='features')): []\n"
     ]
    }
   ],
   "source": [
    "print(f\"loss: {loss}\")\n",
    "for k,v in jax.tree.leaves_with_path(aux): print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d9c142",
   "metadata": {},
   "source": [
    "And using the `is_state_update` function from common we can find it and store it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f8b6840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: [50340 50340 50340 50340] - new_state: [6. 6. 6. 6.]\n",
      "id: [26007 26007 26007 26007] - new_state: [1. 1. 1. 1.]\n",
      "id: 50340 - new_state: 6.0\n",
      "id: 26007 - new_state: 1.0\n"
     ]
    }
   ],
   "source": [
    "# extract state updates from the aux\n",
    "def is_state_update(x):\n",
    "    return isinstance(x, tuple) and isinstance(x[0], StateIndex)\n",
    "state_index_to_update = [\n",
    "            (x[0].id, x[1])\n",
    "            for x in jax.tree.leaves(aux, is_leaf=is_state_update)\n",
    "            if is_state_update(x)\n",
    "            ]\n",
    "for i,j in state_index_to_update: print(f\"id: {i} - new_state: {j}\")\n",
    "\n",
    "# for multisample losses, as standard we only keep the first new generated state\n",
    "state_index_to_update = {int(k[0].squeeze()): v[0] for k,v in state_index_to_update}\n",
    "for i,j in state_index_to_update.items(): print(f\"id: {i} - new_state: {j}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40b73b9",
   "metadata": {},
   "source": [
    "Once collected the new states, we need to match their `id` with the respective losses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce87fff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(StatefulLoss(state_index=StateIndex(id=np.int32(50340)), state=5.0),\n",
       " StatefulLoss(state_index=StateIndex(id=np.int32(26007)), state=0.0))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def has_state_index(m):\n",
    "    return (\n",
    "        hasattr(m, \"state_index\")\n",
    "        and isinstance(m.state_index, StateIndex))\n",
    "def get_modules_to_update(loss):\n",
    "    return tuple([\n",
    "            x\n",
    "            for x in jax.tree.leaves(loss, is_leaf=has_state_index)\n",
    "            if has_state_index(x)\n",
    "            ])\n",
    "get_modules_to_update(loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2b0317",
   "metadata": {},
   "source": [
    "To actually perform in-place replacement, jax does not have easy support, luckily equinox does with the `tree_at` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6529c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_fn(module):\n",
    "    return module.update_state(state_index_to_update[int(module.state_index.id)])\n",
    "loss_fn = eqx.tree_at(where=get_modules_to_update, \n",
    "                      pytree=loss_fn, \n",
    "                      replace_fn=replace_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0444c5",
   "metadata": {},
   "source": [
    "Finally verify that the state update has been done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36f825ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(StatefulLoss(state_index=StateIndex(id=np.int32(50340)), state=6.0),\n",
       " StatefulLoss(state_index=StateIndex(id=np.int32(26007)), state=1.0))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_modules_to_update(loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7448b38",
   "metadata": {},
   "source": [
    "The implementation of the `has_state_index` and `is_state_update` is stored in `mosaic/source/common.py`, while the `update_state` function is in the `mosaic/source/optimizer.py`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mosaic (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
